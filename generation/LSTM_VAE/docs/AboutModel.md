# 変分オートエンコーダを用いた分子生成
生成を制御する機構を持つ分子生成モデルとして変分オートエンコーダにもとづく分子生成モデルを説明する。

# 変分ベイズ法
**変分オートエンコーダ**（VAE）とは、変分ベイズ法を用いて定義されるオートエンコーダ型のニューラルネットワークである。**オートエンコーダ**（auto-encoder, 自己符号化器）とは、データを実数値ベクトルに変換するエンコーダと実数値ベクトルからデータを復元するデコーダの対のことである。

## ベイズ推論（Bayesian inference）
ベイズ推測はデータに相当する確率変数Xとデータにもとづいて推測したい確率変数Zをもとに定義される手続きことである。データに相当する確率変数Xはデータ単体とは限らず、複数のデータから成るサンプルなどの場合もある。一般的なベイズ推論ではデータによって推測したい未知量のすべてとなる。例えば、パラメトリックモデルのパラメータもZに含めることがある。

ここでデータを観測していな状態でのZに対する事前知識$pz(x)$を**事前分布**という。また$Z=z$が与えられたもとで、観測されるデータ$X$が従う確率分布を$p_{X|Z}(x|z)$として、$p_z$と$p_{X|Z}$が既知であるとする。このとき、データ$X$に関する周辺分布
$$
p_X(x) = \int p_{X|Z}(x|z) p_Z(z) dz
$$

を用いて、実現値$X=x$が与えられた下での$Z$の事後分布が
$$
p_{Z|X}(z|x) = \frac{p_{X|Z}(x|z) p_Z(z)}{p_X(x)}
 = \frac{p_{X|Z}(x|z) p_Z(z)}{\int p_{X|Z}(x|z) p_Z(z) dz}
 \propto p_{X|Z}(x|z) p_Z(z)
$$
と導出できる。これを**ベイズの法則**あるいは**ベイズの定理**という。つまり、推測したい未知量$Z$に関する知識が、事前の知識$p_Z$から事後的な知識$p_{Z|X}$に更新されたことを表現している。このように、ベイズ推測は、推測したい確率変数を$Z$として確率モデルを作り、$Z$に関する事後分布を計算することで$Z$の取りそうな値を確率分布の形で知るための手法である。

しかしながら、周辺分布$p_X(x)$の計算には一般的に膨大な時間を要することが多く、事後分布を計算することが困難であることが多いため、厳密な計算はあきらめ、マルコフ連鎖モンテカルロ法や変分ベイズ法を用いる。とくに、変分ベイズ法はニューラルネットワークとの相性が良いため、ニューラルネットワークと組み合わせて使われることが多い。

## 変分ベイズ法（variational Baysian method）
**変分ベイズ法**は事後分布$p_{Z|X}$が計算困難な状況下でパラメータ$\phi$で特徴づけられるパラメトリックな確率モデル$q_{\phi}$を導入し、それを事後分布$p_{Z|X}$になるべく近づけるような$\phi^*$を求め、得られた$q_{\phi^*}$を事後分布の近似とする手法である。この$q_{\phi}$のことを変分分布（variational distribution）と呼ぶ。事後分布を近似するような変分分布$q_{\phi}$を求めるためには事後分布と変分分布の間の近さを測る尺度を用いて最適化問題として定式化したうえでその最小化問題を解く手法が必要になる。

### 事後分布近似の最適化問題としての定式化
事後分布と変分分布の近さを測る手法として**KL情報量**を用いる。(KL:カルバック・ライブラー情報量とは、2つの確率分布の違いを数量化したもの)以下のように、交差エントロピーから情報エントロピーを引くだけである。
$$
D_{KL}(P||Q) = H(P, Q) - H(P)
$$

今回の例ではKL情報量を最小化するパラメータ$\phi^*$を求めることが目的となる。

$$
\phi^* = \argmax_{\phi} D_{\mathrm{KL}}(q_{\phi}(z) \| p_{Z|X}(z | x))
$$
これより、$\phi^*$を求め、$q_{\phi^*}(z)$を事後分布$p_{Z|X}(z | x)$の近似とするのが変分ベイズ法である。ただし、このままでは計算式中の$p_{Z|X}$が計算困難であるから計算できない。そこで、計算可能な目的関数を持つ最適化問題を導出する。
$$
\begin{aligned}
&D_{\mathrm{KL}} (q_{\phi}(z) \| p_{Z|X}(z | x)) \\
&= \int q_{\phi}(z) \log \left( \frac{q_{\phi}(z)}{p_{Z|X}(z | x)} \right) dz \\
&= \int q_{\phi}(z) \log \left( \frac{q_{\phi}(z) p_X(x)}{p_{X, Z}(x, z)} \right) dz \\
&= \int q_{\phi}(z) \left[ -\log \left( \frac{p_{X, Z}(x, z)}{q_{\phi}(z)} \right) + \log p_X(x) \right] dz \\
&= -\mathbb{E}_{Z \sim q_{\phi}} [\log p_{X, Z}(x, Z)] + \mathbb{E}_{Z \sim q_{\phi}}[\log q_{\phi}(Z)] + \log p_X(x)
\end{aligned}
$$

となる。上式において$\log p_X(x)$は$q_{\phi}$に依存しないため、最適解を求めるうえでは無視できる。よって、
$$
\phi^* = \argmax_{\phi} - \mathbb{E}_{Z \sim q_{\phi}} [\log p_{X, Z}(x, Z)] + \mathbb{E}_{Z \sim q_{phi}} [\log q_{\phi} (Z)]
$$
という最適化問題を解けばよい。ここで、$X$と$Z$の同時分布$p_{X, Z}$は一般に容易に計算できる。期待値に関してもモンテカルロ近似することで近似値を計算することができる。
